{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahahaha11/LION_DEN/blob/Chi's-Branch/xg_boost_trial_RFE_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r86oDwJMX-cE",
        "outputId": "4ec858b8-ff33-4fdc-e780-b0bc79e94429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = pd.read_pickle(\"/content/drive/MyDrive/lions_den_data/filtered_features_RFE.pkl\")\n",
        "df_2.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ_uXM9WYcTZ",
        "outputId": "f43f50e0-ae4f-4c6a-9e84-6ca2c0ea53a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['longitude', 'latitude', 'numOfPhotos', 'livingAreaSqFt',\n",
              "       'avgSchoolRating', 'numOfBathrooms', 'Income', 'MORTGAGE30US',\n",
              "       'MEDLISPRIPERSQUFEE12420', 'hasAssociation', 'latestPrice',\n",
              "       'latest_saledate'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = df_2.drop(columns=['latest_saledate'])\n",
        "df_2.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4BI-lUIdlNe",
        "outputId": "e2e59258-43cc-4b70-f5c5-195b07c428b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['longitude', 'latitude', 'numOfPhotos', 'livingAreaSqFt',\n",
              "       'avgSchoolRating', 'numOfBathrooms', 'Income', 'MORTGAGE30US',\n",
              "       'MEDLISPRIPERSQUFEE12420', 'hasAssociation', 'latestPrice'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################ BASE XGB ##########################\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Assume df_2 is already loaded into your environment\n",
        "# df_2 = pd.read_csv('your_file.csv')  # example loading method\n",
        "\n",
        "# Define the target variable and features\n",
        "target = 'latestPrice'\n",
        "features = df_2.columns.drop(target)  # all columns except target\n",
        "\n",
        "X = df_2[features]\n",
        "y = df_2[target]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "\n",
        "X = df_2.drop(columns=['latestPrice'])\n",
        "\n",
        "# FIRST SPLIT\n",
        "n_train = int(0.8 * len(df_2))\n",
        "train = df_2.iloc[:n_train]\n",
        "test  = df_2.iloc[n_train:]\n",
        "\n",
        "X_train = train.drop(columns=['latestPrice'])\n",
        "y_train = train['latestPrice']\n",
        "X_test = test.drop(columns=['latestPrice'])\n",
        "y_test = test['latestPrice']\n",
        "\n",
        "\n",
        "# Create a pipeline with scaling and XGBoost regressor\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('xgb', xgb.XGBRegressor(\n",
        "        objective='reg:squarederror',  # standard objective for regression\n",
        "        random_state=11,\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        reg_alpha=0.1,  # L1 regularization\n",
        "        reg_lambda=1.0  # L2 regularization\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Optionally, you can use GridSearchCV to tune hyperparameters including regularization parameters\n",
        "param_grid = {\n",
        "    'xgb__n_estimators': [100, 200],\n",
        "    'xgb__learning_rate': [0.05, 0.1, 0.2],\n",
        "    'xgb__max_depth': [3, 5, 7],\n",
        "    'xgb__reg_alpha': [0, 0.1, 0.5],\n",
        "    'xgb__reg_lambda': [0.5, 1.0, 2.0]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the model on training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and its parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Test Mean Squared Error: {mse:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVIT67pJYuNW",
        "outputId": "bd88efdb-c5a5-41a5-b4ea-bbb33d133507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Test Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"Test R^2 Score: {r2:.2f}\")"
      ],
      "metadata": {
        "id": "vYdc6LZNbkJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train_pred = grid_search.predict(X_train)\n",
        "y_test_pred = grid_search.predict(X_test)\n",
        "\n",
        "\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "print(\"Training Metrics:\")\n",
        "print(f\"  R²:   {train_r2:.3f}\")\n",
        "print(f\"  RMSE: {train_rmse:,.3f}\")\n",
        "\n",
        "print(\"\\nValidation Metrics:\")\n",
        "print(f\"  R²:   {test_r2:.3f}\")\n",
        "print(f\"  RMSE: {test_rmse:,.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9Fi2U3OgkJc",
        "outputId": "4d5cbf05-f6ea-41f8-921e-a860704fa0fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Metrics:\n",
            "  R²:   0.878\n",
            "  RMSE: 156,522.705\n",
            "\n",
            "Validation Metrics:\n",
            "  R²:   0.660\n",
            "  RMSE: 276,054.394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###################### TRYTING XGB WITH GWR ################### GWR using mgwr library: MAIN : output -> local_betas ############\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from mgwr.gwr import GWR\n",
        "from mgwr.sel_bw import Sel_BW\n",
        "\n",
        "coords = X_train[['latitude', 'longitude']].values\n",
        "# dropping : garageSpaces and parkingSpaces are perfectly collinear (their correlation is 1 and their VIFs are infinite)\n",
        "X_ = X_train.select_dtypes(include=['number']).drop(columns=['latitude', 'longitude', 'latest_saledate', 'parkingSpaces', 'MORTGAGE30US', 'MEDLISPRIPERSQUFEE12420'],\n",
        "    errors='ignore'\n",
        ").values\n",
        "\n",
        "y_ = y_train.values.reshape(-1, 1)\n",
        "X_gwr = np.hstack([np.ones((X_.shape[0], 1)), X_])\n",
        "\n",
        "# using a fixed band width\n",
        "fixed_bw = 0.3\n",
        "\n",
        "gwr_model = GWR(\n",
        "    coords,       # (n, 2)\n",
        "    y_,           # (n, 1)\n",
        "    X_gwr,        # (n, p) [including intercept]\n",
        "    bw=fixed_bw,\n",
        "    kernel='gaussian',  # Gaussian kernel\n",
        "    fixed=True,         # fixed distance bandwidth\n",
        "    spherical=False\n",
        ").fit()\n",
        "\n",
        "local_betas = gwr_model.params  # shape (n, p)\n",
        "print(\"Local betas shape:\\n\", local_betas.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52nGMZ0nioUe",
        "outputId": "5db9b82f-e1a5-493b-8b6c-4a06f37c00ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local betas shape:\n",
            " (12016, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################################### XGB with Local Slopes #################################################\n",
        "# MODEL 0 \"USING local_betas\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "X_xgb = X_train.select_dtypes(include=['number']).drop(\n",
        "    columns=['latitude', 'longitude', 'latest_saledate', 'parkingSpaces'],\n",
        "    errors='ignore'\n",
        ").values\n",
        "print(\"X_xgb shape:\", X_xgb.shape)\n",
        "\n",
        "# local_betas are obtained from the GWR model; its shape is (n, p).\n",
        "local_betas = gwr_model.params\n",
        "print(\"local_betas shape:\", local_betas.shape)\n",
        "\n",
        "# local_slopes are defined by dropping the intercept column (first column) from local_betas.\n",
        "# This gives us an array of shape (n, p-1).\n",
        "local_slopes = local_betas[:, 1:]\n",
        "\n",
        "X_aug = np.hstack([X_xgb, local_slopes])\n",
        "print(\"Augmented feature shape:\", X_aug.shape)\n",
        "\n",
        "y_array = y_.ravel()\n",
        "\n",
        "\n",
        "n_total = X_aug.shape[0]\n",
        "n_train = int(0.8 * n_total)\n",
        "\n",
        "X_train = X_aug[:n_train]\n",
        "y_train = y_array[:n_train]\n",
        "X_test = X_aug[n_train:]\n",
        "y_test = y_array[n_train:]\n",
        "\n",
        "# Create a pipeline with scaling and XGBoost regressor\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('xgb', xgb.XGBRegressor(\n",
        "        objective='reg:squarederror',  # standard objective for regression\n",
        "        random_state=11,\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        reg_alpha=0.1,  # L1 regularization\n",
        "        reg_lambda=1.0  # L2 regularization\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Optionally, you can use GridSearchCV to tune hyperparameters including regularization parameters\n",
        "param_grid = {\n",
        "    'xgb__n_estimators': [100, 200],\n",
        "    'xgb__learning_rate': [0.05, 0.1, 0.2],\n",
        "    'xgb__max_depth': [3, 5, 7],\n",
        "    'xgb__reg_alpha': [0, 0.1, 0.5],\n",
        "    'xgb__reg_lambda': [0.5, 1.0, 2.0]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the model on training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and its parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Test Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"Test R^2 Score: {r2:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JCqe2Tvltyp",
        "outputId": "aa45d2db-b175-428a-a603-16afa3db9b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_xgb shape: (12016, 31)\n",
            "local_betas shape: (12016, 30)\n",
            "Augmented feature shape: (12016, 60)\n",
            "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
            "Best parameters found:  {'xgb__learning_rate': 0.2, 'xgb__max_depth': 3, 'xgb__n_estimators': 100, 'xgb__reg_alpha': 0, 'xgb__reg_lambda': 2.0}\n",
            "Test Mean Squared Error: 57102795916.00\n",
            "Test R^2 Score: 0.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################## CHECK OVER FITTING ##########################\n",
        "\n",
        "y_train_pred = grid_search.predict(X_train)\n",
        "y_test_pred = grid_search.predict(X_test)\n",
        "\n",
        "\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "print(\"Training Metrics:\")\n",
        "print(f\"  R²:   {train_r2:.3f}\")\n",
        "print(f\"  RMSE: {train_rmse:,.3f}\")\n",
        "\n",
        "print(\"\\nValidation Metrics:\")\n",
        "print(f\"  R²:   {test_r2:.3f}\")\n",
        "print(f\"  RMSE: {test_rmse:,.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGMJcVLunNMA",
        "outputId": "f7190017-99e6-4465-f78d-521142a37450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Metrics:\n",
            "  R²:   0.867\n",
            "  RMSE: 165,379.131\n",
            "\n",
            "Validation Metrics:\n",
            "  R²:   0.680\n",
            "  RMSE: 238,961.913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PffgTTfS4SOP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}